{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c19407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.combine import SMOTEENN \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import pickle\n",
    "import sqlalchemy as sa\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af207ca5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes before fit Counter({0: 4130, 1: 1495})\n",
      "The number of classes after fit Counter({1: 2497, 0: 2055})\n",
      "\n",
      "***************Test Data Evaluation***************\n",
      "Confusion Matrix :\n",
      " [[394  26]\n",
      " [ 29 462]]\n",
      "Accuracy : 0.9396267837541163\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93       420\n",
      "           1       0.95      0.94      0.94       491\n",
      "\n",
      "    accuracy                           0.94       911\n",
      "   macro avg       0.94      0.94      0.94       911\n",
      "weighted avg       0.94      0.94      0.94       911\n",
      "\n",
      "*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#\n",
      "\n",
      "**************Train Data Evaluation***************\n",
      "Confusion Matrix :\n",
      " [[1534  101]\n",
      " [  66 1940]]\n",
      "Accuracy : 0.9541334798132382\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1635\n",
      "           1       0.95      0.97      0.96      2006\n",
      "\n",
      "    accuracy                           0.95      3641\n",
      "   macro avg       0.95      0.95      0.95      3641\n",
      "weighted avg       0.95      0.95      0.95      3641\n",
      "\n",
      "Prediccted Class= [0]\n",
      "Probablity= [0.286428]\n"
     ]
    }
   ],
   "source": [
    "class Telecom_customer():\n",
    "    \n",
    "# Data Gathering & Data Analysis\n",
    "    def get_data(self):\n",
    "        \n",
    "        Engine=sa.create_engine(\"mysql+pymysql://root:Pratiksha2501@localhost:3306/project\")\n",
    "        self.churn_df = pd.read_sql_table('telco_customer_churn',Engine)\n",
    "        \n",
    "# Feature Selection\n",
    "    def feature_selection(self):\n",
    "\n",
    "        # Total charges are in object dtype so convert into Numerical feature \n",
    "        self.churn_df['Total_Charges'] = pd.to_numeric(self.churn_df['Total_Charges'], errors='coerce')\n",
    "        \n",
    "        # replace NaN values with mean value\n",
    "        self.churn_df.Total_Charges = self.churn_df.Total_Charges.fillna(self.churn_df.Total_Charges.median())\n",
    "        \n",
    "        features = ['Gender','Senior_Citizen','Partner','Dependents','Tenure_Months','Phone_Service','Multiple_Lines','Internet_Service',\n",
    "                 'Online_Security','Online_Backup','Device_Protection','Tech_Support','Streaming_TV','Streaming_Movies','Contract',\n",
    "                 'Paperless_Billing','Payment_Method','Monthly_Charges','Total_Charges']\n",
    "        \n",
    "        # Categorical feature\n",
    "        self.categorical_feature = {feature for feature in  self.churn_df.columns if  self.churn_df[feature].dtypes == 'O'}\n",
    "        \n",
    "        \n",
    "        # Label Encoding\n",
    "        encoder = LabelEncoder()\n",
    "        for feature in self.categorical_feature:\n",
    "             self.churn_df[feature] = encoder.fit_transform( self.churn_df[feature])\n",
    "            \n",
    "        self.churn_df.drop(['CustomerID','Count', 'Country', 'State', 'City','Zip_Code','Lat_Long','Longitude',\n",
    "                       'Latitude','Churthn_Label','Churn_Score','CLTV','Churn_Reason'],axis=1,inplace=True)\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"preprocess data and return model trainable data\"\"\"\n",
    "        self.X = self.churn_df.drop(['Churn_Value'],axis=1)\n",
    "        self.Y = self.churn_df['Churn_Value']\n",
    "        \n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.X,self.Y,test_size=0.2, \n",
    "                                                                                random_state=2,stratify=self.Y)\n",
    "    \n",
    "    def train_model(self):\n",
    "        \"\"\"trains model on data and return model object\"\"\"\n",
    "        #Model Training/Building\n",
    "        random_os = RandomOverSampler(sampling_strategy=0.7)\n",
    "        self.x_train_ros, self.y_train_ros = random_os.fit_resample(self.x_train,self.y_train)\n",
    "\n",
    "    def get_model_results(self):\n",
    "        \"\"\"returns performance of model on train and test data\"\"\"\n",
    "        # Using SMOTENN Technique\n",
    "        st=SMOTEENN()\n",
    "        self.x_train_st, self.y_train_st = st.fit_resample(self.x_train, self.y_train)\n",
    "        print(\"The number of classes before fit {}\".format(Counter(self.y_train)))\n",
    "        print(\"The number of classes after fit {}\".format(Counter(self.y_train_st)))\n",
    "        \n",
    "        #splitting the over sampling dataset \n",
    "        self.x_train_sap, self.x_test_sap, self.y_train_sap, self.y_test_sap = train_test_split(self.x_train_st, self.y_train_st, test_size=0.2)\n",
    "        \n",
    "        # Random forest classifier\n",
    "        self.Rfc_sampling = RandomForestClassifier(n_estimators=150,criterion='gini', max_depth=15, min_samples_leaf=10, min_samples_split=6)\n",
    "        self.Rfc_sampling.fit(self.x_train_sap, self.y_train_sap)\n",
    "        \n",
    "\n",
    "\n",
    "    def test_evaluation(self,string):\n",
    "        # Model Evaluation Testing Data\n",
    "        print(string.center(50,'*'))\n",
    "    \n",
    "        self.test_pred = self.Rfc_sampling.predict(self.x_test_sap)\n",
    "        cnf_matrix = confusion_matrix(self.y_test_sap, self.test_pred)\n",
    "        print('Confusion Matrix :\\n', cnf_matrix)\n",
    "    \n",
    "        accuracy = accuracy_score(self.y_test_sap, self.test_pred)\n",
    "        print('Accuracy :', accuracy)\n",
    "    \n",
    "        clf_report = classification_report(self.y_test_sap, self.test_pred )\n",
    "        print('Classification Report :\\n', clf_report)\n",
    "    \n",
    "    def train_evaluation(self,string):\n",
    "        # Model Evaluatioon Training Data\n",
    "        print(string.center(50,'*'))\n",
    "    \n",
    "        self.train_pred = self.Rfc_sampling.predict(self.x_train_sap)\n",
    "        cnf_matrix = confusion_matrix(self.y_train_sap, self.train_pred)\n",
    "        print('Confusion Matrix :\\n', cnf_matrix)\n",
    "    \n",
    "        accuracy = accuracy_score(self.y_train_sap, self.train_pred)\n",
    "        print('Accuracy :', accuracy)\n",
    "    \n",
    "        clf_report = classification_report(self.y_train_sap, self.train_pred)\n",
    "        print('Classification Report :\\n', clf_report)\n",
    "        \n",
    "        return self.churn_df\n",
    "\n",
    "    def load_file(self):\n",
    "        with open('RandomForest_model.pkl', 'wb') as f:\n",
    "            pickle.dump(self.Rfc_sampling, f)\n",
    "            \n",
    "        # Load the Model back from file\n",
    "        with open('RandomForest_model.pkl', 'rb') as file:  \n",
    "            self.load_model = pickle.load(file)\n",
    "            \n",
    "            \n",
    "    def new_data(self):\n",
    "        Gender = 'Female'\n",
    "        Senior_Citizen = 'No'\n",
    "        Partner = 'Yes'\n",
    "        Dependents = 'No'\n",
    "        Tenure_Months = 72\n",
    "        Phone_Service = 'Yes'\n",
    "        Multiple_Lines = 'No'\n",
    "        Internet_Service = 'No'\n",
    "        Online_Security = 'No internet service'\n",
    "        Online_Backup = 'No internet service'\n",
    "        Device_Protection = 'No internet service'\n",
    "        Tech_Support = 'No internet service'\n",
    "        Streaming_TV = 'No internet service'\n",
    "        Streaming_Movies = 'No internet service'\n",
    "        Contract = 'Two year'\n",
    "        Paperless_Billing = 'Yes'\n",
    "        Payment_Method = 'Bank transfer (automatic)'\n",
    "        Monthly_Charges = 21.15\n",
    "        Total_Charges = 1419.4\n",
    "        \n",
    "        data = [[Gender,Senior_Citizen,Partner,Dependents,Tenure_Months,Phone_Service,Multiple_Lines,Internet_Service,\n",
    "                 Online_Security,Online_Backup,Device_Protection,Tech_Support,Streaming_TV,Streaming_Movies,Contract,\n",
    "                 Paperless_Billing,Payment_Method,Monthly_Charges,Total_Charges]]\n",
    "\n",
    "        df = pd.DataFrame(data, columns=['Gender','Senior_Citizen','Partner','Dependents','Tenure_Months','Phone_Service',\n",
    "                                         'Multiple_Lines','Internet_Service','Online_Security','Online_Backup',\n",
    "                                         'Device_Protection','Tech_Support','Streaming_TV','Streaming_Movies','Contract',\n",
    "                                         'Paperless_Billing','Payment_Method','Monthly_Charges','Total_Charges'])\n",
    "        \n",
    "#         print(self.load_model.score(self.x_test_sap, self.y_test_sap))\n",
    "\n",
    "        for feature in df.columns:\n",
    "            if df[feature].dtypes == 'object':\n",
    "                categorical_feature = feature\n",
    "#                 print(categorical_feature)\n",
    "    \n",
    "        encoder = LabelEncoder()\n",
    "        for feature in df.columns:\n",
    "            if df[feature].dtypes == 'object':\n",
    "                df[feature] = encoder.fit_transform(df[feature])\n",
    "        \n",
    "        single = self.load_model.predict(df)\n",
    "        probability = self.load_model.predict_proba(df)[:,1]\n",
    "        \n",
    "        print('Prediccted Class=',single)\n",
    "        print('Probablity=',probability)\n",
    "        \n",
    "#         self.churn_df.to_csv('Telecom_customer_churn.csv')\n",
    "#         return df,self.churn_df\n",
    "            \n",
    "        \n",
    "obj=Telecom_customer()\n",
    "obj.get_data()\n",
    "obj.feature_selection()\n",
    "obj.preprocess_data()\n",
    "obj.train_model()\n",
    "obj.get_model_results()\n",
    "print()\n",
    "obj.test_evaluation('Test Data Evaluation')\n",
    "print('*#'*30)\n",
    "print()\n",
    "obj.train_evaluation('Train Data Evaluation')\n",
    "obj.load_file()\n",
    "obj.new_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e3538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
